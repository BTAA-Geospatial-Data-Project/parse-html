{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The script aims to parse HTML elements for the Illinois Geospatial Data Clearinghouse\n",
    "and extract parsed content into a local CSV. The progress is maintained on GitHub\n",
    "(https://github.com/BTAA-Geospatial-Data-Project/parse-html).\n",
    "\n",
    "\n",
    "Files\n",
    "-----\n",
    "x.csv\n",
    "\tA local csv file stores existing urls that are prepared to parse.\n",
    "output_yyyymmdd.csv\n",
    "\tThe output file after parsing and it is followed by the action date.\n",
    "\n",
    "\n",
    "Developers\n",
    "----------\n",
    "Original created on xxxxx\n",
    "Created by Karen Majewicz  @karenmajewicz\n",
    "\n",
    "Updated December 14, 2020\n",
    "Updated by Ziying Cheng  @Ziiiiing\n",
    "\n",
    "Updated May 26, 2021 for Illinois Geospatial Data Clearinghouse\n",
    "\n",
    "Updated June 2, 2021 for MSU Digital Library\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coated-display",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing https://d.lib.msu.edu/maps/400/datastream/MODS/view/\n",
      "Parsing https://d.lib.msu.edu/maps/401/datastream/MODS/view/\n",
      "Parsing https://d.lib.msu.edu/maps/402/datastream/MODS/view/\n",
      "#### Job done ####\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import lxml\n",
    "\n",
    "# extract exising urls from local csv file\n",
    "urls = []\n",
    "\n",
    "with open('06d-01.csv') as fr:\n",
    "    reader = csv.reader(fr)  # reader object\n",
    "    for row in reader:\n",
    "        urls.append(row)\n",
    "\n",
    "\n",
    "# store parsed elements for all urls\n",
    "parseElements = []\n",
    "\n",
    "for url in urls:\n",
    "\n",
    "    page = urllib.request.urlopen(url[0]).read()\n",
    "    soup = BeautifulSoup(page, \"xml\")\n",
    "        \n",
    "        \n",
    "#     url_link = requests.get(url)\n",
    "#     file = bs.BeautifulSoup(url_link.text, \"lxml\")\n",
    "    print(f'Parsing {url[0]}')\n",
    "        \n",
    "\n",
    "    #TITLE - works\n",
    "    titleField = soup.find('mods:title')\n",
    "    try:\n",
    "        title = titleField.text.strip()\n",
    "    except:\n",
    "        title = 'undefined'\n",
    "\n",
    "    \n",
    "    #NOTE - works\n",
    "    descriptionField = soup.find('mods:note')\n",
    "    try:\n",
    "        description = descriptionField.text.strip()\n",
    "    except:\n",
    "        description = 'undefined'\n",
    "\n",
    "    \n",
    "    #creator - works\n",
    "    creatorField = soup.find('mods:namePart')\n",
    "    try:\n",
    "        creator = creatorField.text.strip()\n",
    "    except:\n",
    "        creator = 'undefined'\n",
    "        \n",
    "    #publisher - works\n",
    "    publisherField = soup.find('mods:publisher')\n",
    "    try:\n",
    "        publisher = publisherField.text.strip()\n",
    "    except:\n",
    "        publisher = 'undefined'\n",
    "\n",
    "    \n",
    "    #date - works\n",
    "    dateField = soup.find('mods:dateIssued')\n",
    "    try:\n",
    "        date = dateField.text.strip()\n",
    "    except:\n",
    "        date = 'undefined'\n",
    "\n",
    "    \n",
    "    #coordinates - works\n",
    "    bBoxField = soup.find('mods:coordinates')\n",
    "    try:\n",
    "        bBox = bBoxField.text.strip()\n",
    "    except:\n",
    "        bBox = 'undefined'\n",
    " \n",
    "    \n",
    "    #place name - works\n",
    "    placeNameField = soup.find('mods:geographic')\n",
    "    try:\n",
    "        placeName = placeNameField.text.strip()\n",
    "    except:\n",
    "        placeName = 'undefined'\n",
    "    \n",
    "    #scale - works\n",
    "    scaleField = soup.find('mods:scale')\n",
    "    try:\n",
    "        scale = scaleField.text.strip()\n",
    "    except:\n",
    "        scale = 'undefined'\n",
    "    \n",
    "    #library catalog record - works\n",
    "    libField = soup.find('mods:url',{\"note\": \"catalog_record\"})\n",
    "    try:\n",
    "        lib = libField.text.strip()\n",
    "    except:\n",
    "        lib = 'undefined'\n",
    "        \n",
    "    #ARK - works\n",
    "    arkField = soup.find('mods:url',{\"note\": \"ark\"})\n",
    "    try:\n",
    "        ark = arkField.text.strip()\n",
    "    except:\n",
    "        ark = 'undefined'\n",
    "        \n",
    "    #Rights - works\n",
    "    rightsField = soup.find('mods:accessCondition')\n",
    "    try:\n",
    "        rights = rightsField.text.strip()\n",
    "    except:\n",
    "        rights = 'undefined'\n",
    "        \n",
    "        \n",
    "        \n",
    "    language = 'eng'\n",
    "    provider = 'University of Michigan'\n",
    "    resourceClass = 'Maps'\n",
    "    resourceType = 'Cadastral maps'\n",
    "    subject = 'Real Property|Landowners'\n",
    "    accessRights = 'Public'\n",
    "    memberOf = '06d-01'\n",
    "    fileType = 'TIFF'\n",
    "    code = '06d-01'\n",
    "    status = 'Active'\n",
    "    accrualMethod = 'MODS'\n",
    "    dateAccessioned = '2021-06-02'\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "   \n",
    "                \n",
    "#     #combine the scraped information\n",
    "    parseElements.append([url,title,description,language,creator,publisher,provider,resourceClass,resourceType,subject,date,bBox,placeName,scale,fileType,lib,ark,memberOf,code,accessRights,status,dateAccessioned])\n",
    "\n",
    "# # generate action date with format YYYYMMDD    \n",
    "    \n",
    "actionDate = time.strftime('%Y%m%d')\n",
    "\n",
    "# # write outputs to local csv file\n",
    "with open(f'output_06d-01_{actionDate}.csv', 'w') as fw:\n",
    "    fields = ['link','Title','Description','Language','Creator','Publisher','Provider','Resource Class','Resource Type','Subject',\n",
    "              'Date Issued','Bounding Box','Spatial Coverage','Scale','Format','Documentation','Identifier','Member Of','Code',\n",
    "              'Access Rights','Status','Date Accessioned']\n",
    "\n",
    "    writer = csv.writer(fw)\n",
    "    writer.writerow(fields)           # fieldnames\n",
    "    writer.writerows(parseElements)   # elements\n",
    "\n",
    "    print('#### Job done ####')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-venice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-antique",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
