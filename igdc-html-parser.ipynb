{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The script aims to parse HTML elements for the Illinois Geospatial Data Clearinghouse\n",
    "and extract parsed content into a local CSV. The progress is maintained on GitHub\n",
    "(https://github.com/BTAA-Geospatial-Data-Project/parse-html).\n",
    "\n",
    "\n",
    "Files\n",
    "-----\n",
    "x.csv\n",
    "\tA local csv file stores existing urls that are prepared to parse.\n",
    "output_yyyymmdd.csv\n",
    "\tThe output file after parsing and it is followed by the action date.\n",
    "\n",
    "\n",
    "Developers\n",
    "----------\n",
    "Original created on xxxxx\n",
    "Created by Karen Majewicz  @karenmajewicz\n",
    "\n",
    "Updated December 14, 2020\n",
    "Updated by Ziying Cheng  @Ziiiiing\n",
    "\n",
    "Updated May 26, 2021 for Illinois Geospatial Data Clearinghouse\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "numeric-celebrity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/bedrock-valleys\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-6e873ff0e7de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Parsing {url[0]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mzips\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"application/zip\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mzip\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzips\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdownloadLink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# extract exising urls from local csv file\n",
    "urls = []\n",
    "\n",
    "with open('02a-01-sample.csv') as fr:\n",
    "    reader = csv.reader(fr)  # reader object\n",
    "    for row in reader:\n",
    "        urls.append(row)\n",
    "\n",
    "\n",
    "# store parsed elements for all urls\n",
    "parseElements = []\n",
    "\n",
    "for url in urls:\n",
    "    page = urllib.request.urlopen(url[0]).read()\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    print(f'Parsing {url[0]}')\n",
    "    zips = soup.find(attrs={\"type\":\"application/zip\"})\n",
    "    for zip in zips:\n",
    "        try:\n",
    "            downloadLink = soup.find('a', href=True)\n",
    "            download = downloadLink['href']\n",
    "        except:\n",
    "            download = \"none\" \n",
    "        print(download)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "coated-display",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing https://clearinghouse.isgs.illinois.edu/data/climate/illinois-climate-network-soil-data\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/climate/illinois-climate-network-weather-data\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/coastal/HTEM/lake-michigan-coast-2017\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/coastal/habitat\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/coastal/UAS/IBSP\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/coastal/shorelines/UAS\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/coastal/bathy\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/elevation/illinois-height-modernization-ilhmp\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/elevation/surface-elevation-30-meter-digital-elevation-model-dem\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/elevation/surface-elevation-30-meter-shaded-relief-map\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/elevation/surface-elevation-301-foot-digital-elevation-model-dem\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/elevation/surface-elevation-301-foot-shaded-relief-map\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/bedrock-geology-1967\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/bedrock-geology-2005\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/bedrock-topography\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/bedrock-valleys\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/driftless-areas\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/elevation-base-barlow-limestone\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/elevation-karnak-limestone\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/elevation-new-albany-shale\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/geologic-and-geophysical-maps-ozark-illinois-indiana-and-kentucky-oiink-region\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/glacial-boundaries\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/glacial-drift-thickness-and-character\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/illinois-borehole-temperatures\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/illinois-drill-stem-tests\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/illinois-waterflood-units-1946-2002\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/illinois-well-headers\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/illinois-well-logs\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/illinois-well-tests\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/isgs-field-notes\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/location-points-isgs-wells-and-borings-database\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/moraines-end-moraines-wisconsin-episode\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/oil-gas-and-gas-storage-fields-illinois\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/physiographic-divisions\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/quaternary-deposits-1979\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/quaternary-deposits-1996\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/soil-associations-map-500k\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/stack-unit-mapping-geologic-materials-depth-15-meters\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/structural-features-anticlines-synclines-and-monoclines\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/structural-features-faults-grabens-and-flexures\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/geology/structural-features-polygon-and-point-features\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/hydrology/coarse-grained-materials-within-50-feet-ground-surface-illinois\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/hydrology/flood-zones-unincorporated-areas-one-hundred-and-five-hundred-year\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/hydrology/illinois-center-pivot-irrigation\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/hydrology/illinois-municipal-water-use-2012\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/datasets/illinois-sinkhole-areas\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/datasets/illinois-sinkhole-points\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/hydrology/major-aquifers\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/hydrology/major-bedrock-aquifers-depths-greater-500-feet-below-ground-surface\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/hydrology/major-bedrock-aquifers-within-300-feet-ground-surface\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/hydrology/major-bedrock-aquifers-within-500-feet-ground-surface\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/hydrology/major-sand-and-gravel-aquifers\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/hydrology/northeast-illinois-shallow-bedrock-potentiometric-surface\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/hydrology/potential-agricultural-chemical-contamination-aquifers\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/hydrology/reservoir-observation-network\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/hydrology/sediment-monitoring-network\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/hydrology/shallow-groundwater-wells-network\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/hydrology/streams-and-shorelines\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/hydrology/wetlands-national-wetlands-inventory-1987\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/imagery/1927-historical-aerial-photographs-mississippi-river\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/imagery/1937-1947-illinois-historical-aerial-photography\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/imagery/1998-2001-illinois-digital-orthophoto-quadrangle-doq-data\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/imagery/2000-des-plaines-river-watershed-orthophotography\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/imagery/2004-illinois-naip-digital-orthophoto-quadrangle-data\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/imagery/2005-illinois-chicago-urban-area-orthophotography\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/imagery/2005-illinois-digital-orthophoto-quarter-quadrangle-data\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/imagery/2005-illinois-naip-digital-orthophoto-quadrangle-data\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/imagery/2006-illinois-naip-digital-orthophoto-quadrangle-data\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/imagery/2007-illinois-naip-digital-orthophoto-quadrangle-data\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/imagery/2010-illinois-naip-digital-orthophoto-quadrangle-data\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/imagery/2011-illinois-department-transportation-idot-orthophotography\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/imagery/2011-illinois-naip-digital-orthophoto-quadrangle-data\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/imagery/2012-illinois-naip-digital-orthophoto-quadrangle-data\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/imagery/2014-illinois-naip-digital-orthophoto-quadrangle-data\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/imagery/2015-illinois-naip-digital-orthophoto-quadrangle-data\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/imagery/isgs-historic-photographs\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/infrastructure/municipal-boundaries-incorporated-places-2000\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/infrastructure/political-districts-and-boundaries-2006-and-2007\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/infrastructure/political-townships\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/infrastructure/us-geographic-names-information-system-gnis-illinois\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/land-cover/illinois-gap-analysis-program-land-cover-classification\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/landcover/illinois-landcover-early-1800s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing https://clearinghouse.isgs.illinois.edu/data/land-cover/land-cover-illinois-1999-2000-data\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/land-cover/usda-nass-cropland-data-layer-illinois-1999-2006\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/land-cover/usda-nass-cropland-data-layer-illinois-2007\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/reference/blm-illinois-public-land-survey-system\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/reference/illinois-county-boundaries-polygons-and-lines\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/reference/illinois-plss-townships\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/reference/illinois-public-land-survey-system-plss-boundaries\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/reference/illinois-state-boundary\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/reference/indian-treaty-boundary-lines\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/reference/state-plane-zones\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/reference/universal-transverse-mercator-utm-zones\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/reference/usgs-digital-raster-graphic-drg-files\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/reference/usgs-digital-raster-graphic-drg-mosaic\n",
      "Parsing https://clearinghouse.isgs.illinois.edu/data/reference/usgs-quadrangle-boundaries-and-corner-points-illinois\n",
      "#### Job done ####\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# extract exising urls from local csv file\n",
    "urls = []\n",
    "\n",
    "with open('02a-01-sample.csv') as fr:\n",
    "    reader = csv.reader(fr)  # reader object\n",
    "    for row in reader:\n",
    "        urls.append(row)\n",
    "\n",
    "\n",
    "# store parsed elements for all urls\n",
    "parseElements = []\n",
    "\n",
    "for url in urls:\n",
    "    page = urllib.request.urlopen(url[0]).read()\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    print(f'Parsing {url[0]}')\n",
    "\n",
    "    #TITLE - works\n",
    "    titleField = soup.find(attrs={'id':'page-title'})\n",
    "    title = titleField.text.strip()\n",
    "    \n",
    "    #METADATA LINK - works\n",
    "    try:\n",
    "        metadataLink = soup.find('a', href=True, text = \"Link\")\n",
    "        metadata = metadataLink['href']\n",
    "    except:\n",
    "        metadata = \"none\"\n",
    "        \n",
    "    #SUMMARY - works\n",
    "    try:\n",
    "        summaryField = soup.find(attrs={\"property\":\"content:encoded\"})\n",
    "        summary = summaryField.text.strip()\n",
    "    except:\n",
    "        summary = \"none\"\n",
    "        \n",
    "        \n",
    "    #Everything else - needs to be parsed\n",
    "    \n",
    "    nodeContentField = soup.find(attrs={'class':'node-content'})\n",
    "    nodeContent = nodeContentField.text.strip()\n",
    "\n",
    "    #combine the scraped information\n",
    "    parseElements.append([title,summary,metadata,nodeContent])\n",
    "\n",
    "    \n",
    "# generate action date with format YYYYMMDD    \n",
    "    \n",
    "actionDate = time.strftime('%Y%m%d')\n",
    "\n",
    "# write outputs to local csv file\n",
    "with open(f'output_{actionDate}.csv', 'w') as fw:\n",
    "    fields = ['Title','Description','HTML','Content']\n",
    "\n",
    "    writer = csv.writer(fw)\n",
    "    writer.writerow(fields)           # fieldnames\n",
    "    writer.writerows(parseElements)   # elements\n",
    "\n",
    "    print('#### Job done ####')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-venice",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
